{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Design model (input size, output size, forward pass)\n",
    "# 2) Construct loss and optimizer\n",
    "# 3) Training loop\n",
    "#    - forward pass: compute prediction and loss\n",
    "#    - backward pass: gradients\n",
    "#    - update weights\n",
    "\n",
    "\n",
    "# MNIST\n",
    "# DataLoader, Transformation\n",
    "# Multilayer Neural Net, activation function\n",
    "# Loss and Optimizer\n",
    "# Training Loop (batch training)\n",
    "# Model evaluation\n",
    "# GPU support\n",
    "\n",
    "# ENV: Python 3.9.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorboard\n",
    "# terminal: \n",
    "# $cd folder\n",
    "# $tensorboard --logdir=runs\n",
    "# brower: http://localhost:6006/\n",
    "\n",
    "# Tasks:\n",
    "# 1. show images at TensorBoard\n",
    "# 2. show computaional graph\n",
    "# 3. show training loss/acc with different learning rates\n",
    "#    - change the learning rate: 0.001 --> 0.01\n",
    "#    - change the folder: mnist --> mnist001\n",
    "#    - run the training again\n",
    "#    - refresh tensorboard; you will see two curves.\n",
    "# 4. show precision recall curve\n",
    "\n",
    "# https://pytorch.org/docs/stable/tensorboard.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fnc\n",
    "import torchvision # some builtin datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from PIL import Image as pil\n",
    "pil.ANTIALIAS=pil.LANCZOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = SummaryWriter(\"./runs/mnist\")\n",
    "writer = SummaryWriter(\"./runs/mnist001\") # learning rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "\n",
    "# device config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epoches = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", \n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),#Converts the images into PyTorch tensors. Each image is normalized to have values in the range [0,1]\n",
    "    download=True)\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", \n",
    "    train=False,\n",
    "    transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "# [100, 1, 28, 28]: batch size 100, gray image with size 28 x28\n",
    "\n",
    "#examples = iter(test_loader)\n",
    "#samples, labels = examples.next()\n",
    "#print(samples.shape, labels.shape)\n",
    "\n",
    "# for i in range(6):\n",
    "#    plt.subplot(2, 3, i+1)\n",
    "#    plt.imshow(samples[i][0], cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# Task 1: show images\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image(\"mnist_images\", img_grid)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class MultiCLSNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MultiCLSNeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x) # input: [batch size, 28x28], output: [batch size, 100]\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out) # output: [batch size, 10]\n",
    "        return out\n",
    "\n",
    "model = MultiCLSNeuralNet(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Task 2: show computational graph\n",
    "writer.add_graph(model, samples.to(device).reshape(-1, 28*28))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 2, step 100 / 600, loss =  0.3075\n",
      "epoch 1 / 2, step 200 / 600, loss =  0.1161\n",
      "epoch 1 / 2, step 300 / 600, loss =  0.2285\n",
      "epoch 1 / 2, step 400 / 600, loss =  0.1460\n",
      "epoch 1 / 2, step 500 / 600, loss =  0.1146\n",
      "epoch 1 / 2, step 600 / 600, loss =  0.2495\n",
      "epoch 2 / 2, step 100 / 600, loss =  0.1456\n",
      "epoch 2 / 2, step 200 / 600, loss =  0.0313\n",
      "epoch 2 / 2, step 300 / 600, loss =  0.0787\n",
      "epoch 2 / 2, step 400 / 600, loss =  0.1671\n",
      "epoch 2 / 2, step 500 / 600, loss =  0.1406\n",
      "epoch 2 / 2, step 600 / 600, loss =  0.0639\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_total_steps = len(train_loader)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "for epoch in range(num_epoches):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # print(images.shape) # torch.Size([100, 1, 28, 28]) --> 100, 784\n",
    "        # print(labels.shape) # torch.Size([100])\n",
    "        \n",
    "        images = images.view(batch_size, -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        _, preds = torch.max(y_pred, 1)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # track training performance\n",
    "        running_loss += loss.item()\n",
    "        running_correct += (preds == labels).sum().item()\n",
    "        if (i+1) % 100 == 0: # average loss or acc in 100 steps\n",
    "            writer.add_scalar('training loss', running_loss/100, epoch*num_total_steps + i)\n",
    "            writer.add_scalar('training acc', running_correct/100, epoch*num_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch+1} / {num_epoches}, step {i+1} / {num_total_steps}, loss = {loss: 0.4f}')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 97.0100\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "GT_labels = []\n",
    "pred_probs = []\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(batch_size, -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, y_cls = torch.max(outputs, 1)\n",
    "        probs = fnc.softmax(outputs, dim=1)\n",
    "        \n",
    "        GT_labels.append(labels)\n",
    "        pred_probs.append(probs)\n",
    "\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (y_cls == labels).sum().item()\n",
    "    \n",
    "    acc = 100*n_correct/n_samples\n",
    "    print(f'acc = {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "GT_labels1 = torch.cat(GT_labels).cpu().numpy()\n",
    "print(GT_labels1.shape)\n",
    "\n",
    "pred_probs1 = torch.cat(pred_probs).cpu().numpy()\n",
    "print(pred_probs1.shape)\n",
    "\n",
    "for class_idx in range(pred_probs1.shape[1]):\n",
    "    writer.add_pr_curve(\n",
    "        f'Class {class_idx} Precision Recall',\n",
    "        GT_labels1 == class_idx,\n",
    "        pred_probs1[:, class_idx],\n",
    "        global_step = 0\n",
    "    )\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
